{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"lrwHc9jS8Vdm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684654699157,"user_tz":-480,"elapsed":3105,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}},"outputId":"745b45f5-c077-4925-fd91-35fee1981ffe"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/\n","!git clone -q https://github.com/huggingface/transformers\n","%cd transformers\n","!pip install -q ."],"metadata":{"id":"55TC_InCCNKo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684654755893,"user_tz":-480,"elapsed":44145,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}},"outputId":"128c02a0-ab23-4fd6-92cb-0f40987145bb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/transformers\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["!cp '/content/drive/MyDrive/AI for Education/MATH Dataset/Context_Aware_Ans_Unaware_Finetune/train_ans_unaware_finetune_MATH.csv' /content/transformers/examples/pytorch/summarization\n","!cp '/content/drive/MyDrive/AI for Education/MATH Dataset/Context_Aware_Ans_Unaware_Finetune/test_ans_unaware_finetune_MATH.csv' /content/transformers/examples/pytorch/summarization"],"metadata":{"id":"Zw5xH9xKFnQi","executionInfo":{"status":"ok","timestamp":1684654758196,"user_tz":-480,"elapsed":2352,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["%cd /content/transformers/examples/pytorch/summarization\n","!pip install -r requirements.txt"],"metadata":{"id":"ntsYEti7DMXD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lyyHxeo_5cgW"},"source":["## <h1> 1. BART"]},{"cell_type":"code","source":["!python3 run_summarization.py \\\n","    --model_name_or_path facebook/bart-base \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --train_file 'train_ans_unaware_finetune_MATH.csv' \\\n","    --validation_file 'test_ans_unaware_finetune_MATH.csv' \\\n","    --test_file 'test_ans_unaware_finetune_MATH.csv' \\\n","    --text_column text \\\n","    --summary_column headlines \\\n","    --source_prefix \"generate a math question from context: \" \\\n","    --output_dir  'output-bart' \\\n","    --logging_dir  'output-bart' \\\n","    --per_device_train_batch_size=2 \\\n","    --per_device_eval_batch_size=2 \\\n","    --gradient_accumulation_steps=2 \\\n","    --predict_with_generate=True \\\n","    --learning_rate=0.00005 \\\n","    --num_beams=5 \\\n","    --max_steps=10000 \\\n","    --save_steps=500 \\\n","    --eval_steps=500 \\\n","    --evaluation_strategy steps \\\n","    --load_best_model \\\n","    --overwrite_output_dir "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0m1QnPfBEApO","executionInfo":{"status":"ok","timestamp":1684654684181,"user_tz":-480,"elapsed":851,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}},"outputId":"b084f452-1112-4a97-fcdb-bf49200ce717"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file '/content/run_summarization.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"markdown","source":["## Resume training "],"metadata":{"id":"9KfyzT7HZYRa"}},{"cell_type":"code","source":["%cd /content/transformers/examples/pytorch/summarization\n","!mkdir output-bart"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCUjd62tZU5M","executionInfo":{"status":"ok","timestamp":1684654793435,"user_tz":-480,"elapsed":12,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}},"outputId":"99617aa8-683f-48a9-e6ab-4fb4b39cf5a6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/transformers/examples/pytorch/summarization\n"]}]},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/BART_ANS_UNAWA_MATH/checkpoint-5500 /content/transformers/examples/pytorch/summarization/output-bart/"],"metadata":{"id":"SiJjO_xJZriA","executionInfo":{"status":"ok","timestamp":1684657615963,"user_tz":-480,"elapsed":39913,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# !rm -r /content/transformers/examples/pytorch/summarization/output-T5/checkpoint-2500"],"metadata":{"id":"8WxRBo4-eYkQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3 run_summarization.py \\\n","    --model_name_or_path facebook/bart-base \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --train_file 'train_ans_unaware_finetune_MATH.csv' \\\n","    --validation_file 'test_ans_unaware_finetune_MATH.csv' \\\n","    --test_file 'test_ans_unaware_finetune_MATH.csv' \\\n","    --text_column text \\\n","    --summary_column headlines \\\n","    --source_prefix \"generate a math question from context: \" \\\n","    --output_dir  'output-bart' \\\n","    --logging_dir  'output-bart' \\\n","    --per_device_train_batch_size=2 \\\n","    --per_device_eval_batch_size=2 \\\n","    --gradient_accumulation_steps=2 \\\n","    --predict_with_generate=True \\\n","    --learning_rate=0.00005 \\\n","    --num_beams=5 \\\n","    --max_steps=10000 \\\n","    --save_steps=500 \\\n","    --eval_steps=500 \\\n","    --evaluation_strategy steps \\\n","    --load_best_model "],"metadata":{"id":"Y-rOoz5RZ7a8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684658980487,"user_tz":-480,"elapsed":1361636,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}},"outputId":"64cf0f4b-46d1-40f1-fc21-90c44f650bb5"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-21 08:27:05.116960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","05/21/2023 08:27:09 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n","05/21/2023 08:27:09 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=500,\n","evaluation_strategy=steps,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=2,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=output-bart,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=10000,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_hf,\n","optim_args=None,\n","output_dir=output-bart,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=2,\n","per_device_train_batch_size=2,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=output-bart,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","05/21/2023 08:27:09 - INFO - __main__ - Checkpoint detected, resuming training at output-bart/checkpoint-10000. To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\n","05/21/2023 08:27:10 - INFO - datasets.builder - Using custom data configuration default-c9585ecefb30923a\n","05/21/2023 08:27:10 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n","05/21/2023 08:27:10 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","05/21/2023 08:27:10 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-c9585ecefb30923a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\n","05/21/2023 08:27:10 - WARNING - datasets.builder - Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-c9585ecefb30923a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n","05/21/2023 08:27:10 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-c9585ecefb30923a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\n","100% 3/3 [00:00<00:00, 31.36it/s]\n","[INFO|configuration_utils.py:669] 2023-05-21 08:27:10,613 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n","[INFO|configuration_utils.py:725] 2023-05-21 08:27:10,622 >> Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-base\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.1,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.30.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|tokenization_auto.py:503] 2023-05-21 08:27:10,845 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n","[INFO|configuration_utils.py:669] 2023-05-21 08:27:11,078 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n","[INFO|configuration_utils.py:725] 2023-05-21 08:27:11,080 >> Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-base\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.1,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.30.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 08:27:11,533 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/vocab.json\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 08:27:11,533 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/merges.txt\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 08:27:11,533 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/tokenizer.json\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 08:27:11,533 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 08:27:11,533 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 08:27:11,533 >> loading file tokenizer_config.json from cache at None\n","[INFO|configuration_utils.py:669] 2023-05-21 08:27:11,533 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n","[INFO|configuration_utils.py:725] 2023-05-21 08:27:11,534 >> Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-base\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.1,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.30.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|modeling_utils.py:2523] 2023-05-21 08:27:11,654 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/pytorch_model.bin\n","[INFO|configuration_utils.py:577] 2023-05-21 08:27:13,795 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"no_repeat_ngram_size\": 3,\n","  \"num_beams\": 4,\n","  \"pad_token_id\": 1,\n","  \"transformers_version\": \"4.30.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:3192] 2023-05-21 08:27:16,282 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:3200] 2023-05-21 08:27:16,283 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","[INFO|modeling_utils.py:2828] 2023-05-21 08:27:16,511 >> Generation config file not found, using a generation config created from the model config.\n","05/21/2023 08:27:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-c9585ecefb30923a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a6e530e7d740b3c4.arrow\n","Running tokenizer on validation dataset:   0% 0/5000 [00:00<?, ? examples/s]05/21/2023 08:27:16 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-c9585ecefb30923a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-1b6cc02fd18e198d.arrow\n","05/21/2023 08:27:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-c9585ecefb30923a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f278d45a3d3466f5.arrow\n","[INFO|trainer.py:565] 2023-05-21 08:27:24,784 >> max_steps is given, it will override any value given in num_train_epochs\n","[INFO|trainer.py:2129] 2023-05-21 08:27:24,785 >> Loading model from output-bart/checkpoint-10000.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","[INFO|trainer.py:1779] 2023-05-21 08:27:34,373 >> ***** Running training *****\n","[INFO|trainer.py:1780] 2023-05-21 08:27:34,373 >>   Num examples = 5,503\n","[INFO|trainer.py:1781] 2023-05-21 08:27:34,373 >>   Num Epochs = 8\n","[INFO|trainer.py:1782] 2023-05-21 08:27:34,373 >>   Instantaneous batch size per device = 2\n","[INFO|trainer.py:1783] 2023-05-21 08:27:34,373 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n","[INFO|trainer.py:1784] 2023-05-21 08:27:34,373 >>   Gradient Accumulation steps = 2\n","[INFO|trainer.py:1785] 2023-05-21 08:27:34,373 >>   Total optimization steps = 10,000\n","[INFO|trainer.py:1786] 2023-05-21 08:27:34,377 >>   Number of trainable parameters = 139,420,416\n","[INFO|trainer.py:1806] 2023-05-21 08:27:34,380 >>   Continuing training from checkpoint, will skip to saved global_step\n","[INFO|trainer.py:1807] 2023-05-21 08:27:34,381 >>   Continuing training from epoch 7\n","[INFO|trainer.py:1808] 2023-05-21 08:27:34,381 >>   Continuing training from global step 10000\n","[INFO|trainer.py:1819] 2023-05-21 08:27:34,381 >>   Will skip the first 7 epochs then the first 736 batches in the first epoch.\n","  0% 0/10000 [00:00<?, ?it/s][WARNING|logging.py:280] 2023-05-21 08:27:34,439 >> You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","10001it [00:00, 11129.11it/s][INFO|trainer.py:2052] 2023-05-21 08:27:35,324 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2185] 2023-05-21 08:27:35,324 >> Loading best model from output-bart/checkpoint-5500 (score: 1.4767770767211914).\n","{'train_runtime': 3.7968, 'train_samples_per_second': 10535.127, 'train_steps_per_second': 2633.782, 'train_loss': 8.321926481973384e-05, 'epoch': 7.27}\n","10001it [00:03, 2665.22it/s] \n","[INFO|trainer.py:2904] 2023-05-21 08:27:38,178 >> Saving model checkpoint to output-bart\n","[INFO|configuration_utils.py:458] 2023-05-21 08:27:38,180 >> Configuration saved in output-bart/config.json\n","[INFO|configuration_utils.py:364] 2023-05-21 08:27:38,180 >> Configuration saved in output-bart/generation_config.json\n","[INFO|modeling_utils.py:1836] 2023-05-21 08:27:39,960 >> Model weights saved in output-bart/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2181] 2023-05-21 08:27:39,963 >> tokenizer config file saved in output-bart/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2188] 2023-05-21 08:27:39,964 >> Special tokens file saved in output-bart/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =       7.27\n","  train_loss               =     0.0001\n","  train_runtime            = 0:00:03.79\n","  train_samples            =       5503\n","  train_samples_per_second =  10535.127\n","  train_steps_per_second   =   2633.782\n","05/21/2023 08:27:40 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:3165] 2023-05-21 08:27:40,123 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3167] 2023-05-21 08:27:40,123 >>   Num examples = 3737\n","[INFO|trainer.py:3170] 2023-05-21 08:27:40,123 >>   Batch size = 2\n","[INFO|configuration_utils.py:577] 2023-05-21 08:27:40,127 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"no_repeat_ngram_size\": 3,\n","  \"num_beams\": 4,\n","  \"pad_token_id\": 1,\n","  \"transformers_version\": \"4.30.0.dev0\"\n","}\n","\n","100% 1869/1869 [11:02<00:00,  2.82it/s]\n","***** eval metrics *****\n","  epoch                   =       7.27\n","  eval_gen_len            =    15.9679\n","  eval_loss               =     1.4768\n","  eval_rouge1             =    40.9139\n","  eval_rouge2             =     23.609\n","  eval_rougeL             =    38.8691\n","  eval_rougeLsum          =    38.8264\n","  eval_runtime            = 0:11:02.63\n","  eval_samples            =       3737\n","  eval_samples_per_second =       5.64\n","  eval_steps_per_second   =      2.821\n","05/21/2023 08:38:42 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:3165] 2023-05-21 08:38:42,766 >> ***** Running Prediction *****\n","[INFO|trainer.py:3167] 2023-05-21 08:38:42,766 >>   Num examples = 3737\n","[INFO|trainer.py:3170] 2023-05-21 08:38:42,766 >>   Batch size = 2\n","100% 1869/1869 [10:53<00:00,  2.86it/s]\n","***** predict metrics *****\n","  predict_gen_len            =    15.9679\n","  predict_loss               =     1.4768\n","  predict_rouge1             =    40.9139\n","  predict_rouge2             =     23.609\n","  predict_rougeL             =    38.8691\n","  predict_rougeLsum          =    38.8264\n","  predict_runtime            = 0:10:53.42\n","  predict_samples            =       3737\n","  predict_samples_per_second =      5.719\n","  predict_steps_per_second   =       2.86\n","[INFO|modelcard.py:451] 2023-05-21 08:49:36,563 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Summarization', 'type': 'summarization'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 40.9139}]}\n"]}]},{"cell_type":"code","source":["import os \n","%cd /content/transformers/examples/pytorch/summarization/output-bart\n","for x in os.listdir(\"/content/transformers/examples/pytorch/summarization/output-bart\"):\n","  if x[:5] not in [\"event\", \"check\"]:\n","    print(\"!cp\", x, \"/content/drive/MyDrive/BART_ANS_UNAWA_MATH\")"],"metadata":{"id":"RyGM2gS2iSso"},"execution_count":null,"outputs":[]}]}