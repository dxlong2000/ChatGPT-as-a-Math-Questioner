{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24707,"status":"ok","timestamp":1683438846975,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"},"user_tz":-480},"id":"lrwHc9jS8Vdm","outputId":"ea95ea83-d640-4aaf-a811-d6c335506469"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":42857,"status":"ok","timestamp":1683438961833,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"},"user_tz":-480},"id":"55TC_InCCNKo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc1d1d7e-fcd2-4133-cb88-9d490125a0a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/transformers\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["%cd /content/\n","!git clone -q https://github.com/huggingface/transformers\n","%cd transformers\n","!pip install -q ."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3565,"status":"ok","timestamp":1683438965346,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"},"user_tz":-480},"id":"Zw5xH9xKFnQi"},"outputs":[],"source":["!cp '/content/drive/MyDrive/AI for Education/GSM8K/t5-train.csv' /content/transformers/examples/pytorch/summarization\n","!cp '/content/drive/MyDrive/AI for Education/GSM8K/t5-test.csv' /content/transformers/examples/pytorch/summarization"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19518,"status":"ok","timestamp":1683439003650,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"},"user_tz":-480},"id":"ntsYEti7DMXD","outputId":"dcc3f816-b8c1-49d1-8a0c-46ebe8570565"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score->-r requirements.txt (line 5)) (1.4.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score->-r requirements.txt (line 5)) (1.16.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 6)) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 6)) (2022.10.31)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 6)) (8.1.3)\n","Collecting brotli>=1.0.9\n","  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pybcj>=0.6.0\n","  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n","  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyzstd>=0.14.4\n","  Downloading pyzstd-0.15.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (399 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.3/399.3 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting inflate64>=0.3.1\n","  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multivolumefile>=0.2.3\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Collecting texttable\n","  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n","Collecting pycryptodomex>=3.6.6\n","  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 8)) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 8)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 8)) (1.11.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 8)) (3.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 8)) (3.12.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 8)) (3.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->-r requirements.txt (line 8)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->-r requirements.txt (line 8)) (16.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (2.0.12)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->-r requirements.txt (line 8)) (2.1.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->-r requirements.txt (line 8)) (1.3.0)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=20ed2e05eabfff61f9191be78d8d470f2b6ad9ea0043f2522748dd18c360159c\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: texttable, sentencepiece, brotli, xxhash, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, multidict, inflate64, frozenlist, dill, async-timeout, yarl, rouge-score, responses, py7zr, multiprocess, aiosignal, aiohttp, datasets, evaluate, accelerate\n","Successfully installed accelerate-0.18.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 brotli-1.0.9 datasets-2.12.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 inflate64-0.3.1 multidict-6.0.4 multiprocess-0.70.14 multivolumefile-0.2.3 py7zr-0.20.5 pybcj-1.0.1 pycryptodomex-3.17 pyppmd-1.0.0 pyzstd-0.15.7 responses-0.18.0 rouge-score-0.1.2 sentencepiece-0.1.99 texttable-1.6.7 xxhash-3.2.0 yarl-1.9.2\n"]}],"source":["%cd /content/transformers/examples/pytorch/summarization\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"lyyHxeo_5cgW"},"source":["## <h1> 1. T5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jv86ADdn5Y9V"},"outputs":[],"source":["!python3 run_summarization.py \\\n","    --model_name_or_path t5-base \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --train_file 't5-train.csv' \\\n","    --validation_file 't5-test.csv' \\\n","    --test_file 't5-test.csv' \\\n","    --text_column InputContext \\\n","    --summary_column question \\\n","    --source_prefix \"generate a math question from context: \" \\\n","    --output_dir  'output-T5' \\\n","    --logging_dir  'output-T5' \\\n","    --per_device_train_batch_size=2 \\\n","    --per_device_eval_batch_size=2 \\\n","    --gradient_accumulation_steps=2 \\\n","    --predict_with_generate=True \\\n","    --learning_rate=0.00005 \\\n","    --num_beams=5 \\\n","    --max_steps=2000 \\\n","    --save_steps=500 \\\n","    --eval_steps=500 \\\n","    --evaluation_strategy steps \\\n","    --load_best_model \\\n","    --overwrite_output_dir "]},{"cell_type":"markdown","metadata":{"id":"9KfyzT7HZYRa"},"source":["## Resume training "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1683439003651,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"},"user_tz":-480},"id":"gCUjd62tZU5M","outputId":"0f645bc2-bbb9-435b-a279-1c5ea86ba2f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/transformers/examples/pytorch/summarization\n"]}],"source":["%cd /content/transformers/examples/pytorch/summarization\n","!mkdir output-T5"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"SiJjO_xJZriA","executionInfo":{"status":"ok","timestamp":1683441770912,"user_tz":-480,"elapsed":59747,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}}},"outputs":[],"source":["!cp -r /content/drive/MyDrive/GSM8K_T5_TEMP/checkpoint-7500 /content/transformers/examples/pytorch/summarization/output-T5/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8WxRBo4-eYkQ"},"outputs":[],"source":["# !rm -r /content/transformers/examples/pytorch/summarization/output-T5/checkpoint-2500"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-rOoz5RZ7a8","executionInfo":{"status":"ok","timestamp":1683442755959,"user_tz":-480,"elapsed":892757,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}},"outputId":"91a6339b-6c6c-450d-cb06-777f05322d1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-07 06:44:33.752445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","05/07/2023 06:44:38 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n","05/07/2023 06:44:38 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=500,\n","evaluation_strategy=steps,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=2,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=output-T5,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=10000,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_hf,\n","optim_args=None,\n","output_dir=output-T5,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=2,\n","per_device_train_batch_size=2,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=output-T5,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","05/07/2023 06:44:38 - INFO - __main__ - Checkpoint detected, resuming training at output-T5/checkpoint-10000. To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\n","05/07/2023 06:44:39 - INFO - datasets.builder - Using custom data configuration default-5a71a0c7303eaab4\n","05/07/2023 06:44:39 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n","05/07/2023 06:44:39 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","05/07/2023 06:44:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-5a71a0c7303eaab4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\n","05/07/2023 06:44:39 - WARNING - datasets.builder - Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-5a71a0c7303eaab4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n","05/07/2023 06:44:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-5a71a0c7303eaab4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\n","100% 3/3 [00:00<00:00, 42.11it/s]\n","[INFO|configuration_utils.py:669] 2023-05-07 06:44:39,506 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n","[INFO|configuration_utils.py:725] 2023-05-07 06:44:39,514 >> Model config T5Config {\n","  \"_name_or_path\": \"t5-base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.29.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","[INFO|tokenization_auto.py:502] 2023-05-07 06:44:39,740 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n","[INFO|configuration_utils.py:669] 2023-05-07 06:44:39,964 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n","[INFO|configuration_utils.py:725] 2023-05-07 06:44:39,965 >> Model config T5Config {\n","  \"_name_or_path\": \"t5-base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.29.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","[INFO|tokenization_utils_base.py:1810] 2023-05-07 06:44:40,416 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/spiece.model\n","[INFO|tokenization_utils_base.py:1810] 2023-05-07 06:44:40,416 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/tokenizer.json\n","[INFO|tokenization_utils_base.py:1810] 2023-05-07 06:44:40,416 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1810] 2023-05-07 06:44:40,416 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1810] 2023-05-07 06:44:40,417 >> loading file tokenizer_config.json from cache at None\n","[INFO|configuration_utils.py:669] 2023-05-07 06:44:40,417 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n","[INFO|configuration_utils.py:725] 2023-05-07 06:44:40,418 >> Model config T5Config {\n","  \"_name_or_path\": \"t5-base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.29.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n","[INFO|modeling_utils.py:2524] 2023-05-07 06:44:40,566 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/pytorch_model.bin\n","[INFO|configuration_utils.py:577] 2023-05-07 06:44:44,052 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.29.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:3193] 2023-05-07 06:44:47,453 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:3201] 2023-05-07 06:44:47,454 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:539] 2023-05-07 06:44:47,696 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/generation_config.json\n","[INFO|configuration_utils.py:577] 2023-05-07 06:44:47,696 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.29.0.dev0\"\n","}\n","\n","05/07/2023 06:44:47 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5a71a0c7303eaab4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b47e68ddaa294062.arrow\n","Running tokenizer on validation dataset:   0% 0/1319 [00:00<?, ? examples/s]05/07/2023 06:44:48 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-5a71a0c7303eaab4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-0942169af3c2a456.arrow\n","05/07/2023 06:44:48 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5a71a0c7303eaab4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-08d99db17e4384fc.arrow\n","[INFO|trainer.py:565] 2023-05-07 06:44:54,055 >> max_steps is given, it will override any value given in num_train_epochs\n","[INFO|trainer.py:2121] 2023-05-07 06:44:54,055 >> Loading model from output-T5/checkpoint-10000.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","[INFO|trainer.py:1771] 2023-05-07 06:45:06,398 >> ***** Running training *****\n","[INFO|trainer.py:1772] 2023-05-07 06:45:06,399 >>   Num examples = 7,473\n","[INFO|trainer.py:1773] 2023-05-07 06:45:06,399 >>   Num Epochs = 6\n","[INFO|trainer.py:1774] 2023-05-07 06:45:06,399 >>   Instantaneous batch size per device = 2\n","[INFO|trainer.py:1775] 2023-05-07 06:45:06,399 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n","[INFO|trainer.py:1776] 2023-05-07 06:45:06,399 >>   Gradient Accumulation steps = 2\n","[INFO|trainer.py:1777] 2023-05-07 06:45:06,399 >>   Total optimization steps = 10,000\n","[INFO|trainer.py:1778] 2023-05-07 06:45:06,400 >>   Number of trainable parameters = 222,903,552\n","[INFO|trainer.py:1798] 2023-05-07 06:45:06,401 >>   Continuing training from checkpoint, will skip to saved global_step\n","[INFO|trainer.py:1799] 2023-05-07 06:45:06,401 >>   Continuing training from epoch 5\n","[INFO|trainer.py:1800] 2023-05-07 06:45:06,401 >>   Continuing training from global step 10000\n","[INFO|trainer.py:1811] 2023-05-07 06:45:06,401 >>   Will skip the first 5 epochs then the first 1320 batches in the first epoch.\n","  0% 0/10000 [00:00<?, ?it/s][WARNING|logging.py:280] 2023-05-07 06:45:06,435 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","10001it [00:02, 3699.02it/s] [INFO|trainer.py:2044] 2023-05-07 06:45:09,123 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2177] 2023-05-07 06:45:09,123 >> Loading best model from output-T5/checkpoint-7500 (score: 0.9251402020454407).\n","{'train_runtime': 6.9192, 'train_samples_per_second': 5781.002, 'train_steps_per_second': 1445.25, 'train_loss': 8.176395433233471e-05, 'epoch': 5.35}\n","10001it [00:06, 1448.65it/s]\n","[INFO|trainer.py:2896] 2023-05-07 06:45:13,323 >> Saving model checkpoint to output-T5\n","[INFO|configuration_utils.py:458] 2023-05-07 06:45:13,325 >> Configuration saved in output-T5/config.json\n","[INFO|configuration_utils.py:364] 2023-05-07 06:45:13,326 >> Configuration saved in output-T5/generation_config.json\n","[INFO|modeling_utils.py:1837] 2023-05-07 06:45:16,404 >> Model weights saved in output-T5/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2181] 2023-05-07 06:45:16,405 >> tokenizer config file saved in output-T5/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2188] 2023-05-07 06:45:16,405 >> Special tokens file saved in output-T5/special_tokens_map.json\n","[INFO|tokenization_t5_fast.py:186] 2023-05-07 06:45:16,728 >> Copy vocab file to output-T5/spiece.model\n","***** train metrics *****\n","  epoch                    =       5.35\n","  train_loss               =     0.0001\n","  train_runtime            = 0:00:06.91\n","  train_samples            =       7473\n","  train_samples_per_second =   5781.002\n","  train_steps_per_second   =    1445.25\n","05/07/2023 06:45:16 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:3157] 2023-05-07 06:45:16,756 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3159] 2023-05-07 06:45:16,756 >>   Num examples = 1319\n","[INFO|trainer.py:3162] 2023-05-07 06:45:16,756 >>   Batch size = 2\n","[INFO|configuration_utils.py:577] 2023-05-07 06:45:16,770 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.29.0.dev0\"\n","}\n","\n","100% 660/660 [06:57<00:00,  1.58it/s]\n","***** eval metrics *****\n","  epoch                   =       5.35\n","  eval_gen_len            =    16.5368\n","  eval_loss               =     0.9251\n","  eval_rouge1             =    68.0051\n","  eval_rouge2             =    49.5442\n","  eval_rougeL             =    63.2834\n","  eval_rougeLsum          =    63.3346\n","  eval_runtime            = 0:06:58.44\n","  eval_samples            =       1319\n","  eval_samples_per_second =      3.152\n","  eval_steps_per_second   =      1.577\n","05/07/2023 06:52:15 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:3157] 2023-05-07 06:52:15,209 >> ***** Running Prediction *****\n","[INFO|trainer.py:3159] 2023-05-07 06:52:15,209 >>   Num examples = 1319\n","[INFO|trainer.py:3162] 2023-05-07 06:52:15,209 >>   Batch size = 2\n","100% 660/660 [06:54<00:00,  1.59it/s]\n","***** predict metrics *****\n","  predict_gen_len            =    16.5368\n","  predict_loss               =     0.9251\n","  predict_rouge1             =    68.0051\n","  predict_rouge2             =    49.5442\n","  predict_rougeL             =    63.2834\n","  predict_rougeLsum          =    63.3346\n","  predict_runtime            = 0:06:55.05\n","  predict_samples            =       1319\n","  predict_samples_per_second =      3.178\n","  predict_steps_per_second   =       1.59\n","[INFO|modelcard.py:451] 2023-05-07 06:59:10,635 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Summarization', 'type': 'summarization'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 68.0051}]}\n"]}],"source":["!python3 run_summarization.py \\\n","    --model_name_or_path t5-base \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --train_file 't5-train.csv' \\\n","    --validation_file 't5-test.csv' \\\n","    --test_file 't5-test.csv' \\\n","    --text_column InputContext \\\n","    --summary_column question \\\n","    --source_prefix \"generate a math question from context: \" \\\n","    --output_dir  'output-T5' \\\n","    --logging_dir  'output-T5' \\\n","    --per_device_train_batch_size=2 \\\n","    --per_device_eval_batch_size=2 \\\n","    --gradient_accumulation_steps=2 \\\n","    --predict_with_generate=True \\\n","    --learning_rate=0.00005 \\\n","    --num_beams=5 \\\n","    --max_steps=10000 \\\n","    --save_steps=500 \\\n","    --eval_steps=500 \\\n","    --evaluation_strategy steps \\\n","    --load_best_model "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ady2Gz2Z06l4"},"outputs":[],"source":["%cd /content/transformers/examples/pytorch/summarization/output-T5\n","!cp tokenizer.json /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp generation_config.json /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp all_results.json /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp config.json /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp predict_results.json /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp eval_results.json /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp training_args.bin /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp trainer_state.json /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp spiece.model /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp special_tokens_map.json /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp tokenizer_config.json /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp pytorch_model.bin /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp README.md /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp generated_predictions.txt /content/drive/MyDrive/GSM8K_T5_TEMP\n","!cp train_results.json /content/drive/MyDrive/GSM8K_T5_TEMP\n"]},{"cell_type":"code","source":["import os\n","os.listdir(\"/content/transformers/examples/pytorch/summarization/output-T5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DYa5FEBCG4Y","executionInfo":{"status":"ok","timestamp":1683443203748,"user_tz":-480,"elapsed":8,"user":{"displayName":"Đức Anh Vũ","userId":"03470508044389761859"}},"outputId":"acca632b-099b-4841-c41a-fcbded4f0a94"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['checkpoint-7500',\n"," 'tokenizer.json',\n"," 'events.out.tfevents.1683442335.c47ed2cd9394.13810.2',\n"," 'generation_config.json',\n"," 'checkpoint-9500',\n"," 'all_results.json',\n"," 'config.json',\n"," 'predict_results.json',\n"," 'eval_results.json',\n"," 'training_args.bin',\n"," 'events.out.tfevents.1683439115.c47ed2cd9394.2257.0',\n"," 'trainer_state.json',\n"," 'spiece.model',\n"," 'checkpoint-9000',\n"," 'special_tokens_map.json',\n"," 'events.out.tfevents.1683441906.c47ed2cd9394.13810.0',\n"," 'tokenizer_config.json',\n"," '1683439115.182402',\n"," 'checkpoint-8500',\n"," 'pytorch_model.bin',\n"," 'README.md',\n"," 'generated_predictions.txt',\n"," 'checkpoint-10000',\n"," '1683441906.4165509',\n"," 'train_results.json',\n"," 'checkpoint-8000']"]},"metadata":{},"execution_count":10}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1NSwFBvG1oVfd5_lDElolxHt-MEeCtlyP","timestamp":1682315929087},{"file_id":"1X_PvdvMKoj5DJnufh7MzYJyX3yj2GIMu","timestamp":1682233632811},{"file_id":"1G7ERabrSBQpZyutRBaqUDhQDCbcIa49T","timestamp":1681715816704}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}